{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNy7Kr8VQrhT",
        "outputId": "3d9c7b36-18dc-421c-a321-3efd7a5fb6c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the AI-Driven Sales Assistant!\n",
            "\n",
            "Enter customer name: \"Jane Smith\"\n",
            "\n",
            "Enter customer speech: Sure! Here's a sentence with a neutral sentiment:  \"The product arrived on time, but I haven't had a chance to use it yet.\"\n",
            "\n",
            "[Speech Analysis]\n",
            "Detected Sentiment: NEGATIVE (Confidence: 1.00)\n",
            "\n",
            "[Product Recommendations]\n",
            "Customer not found in CRM.\n",
            "\n",
            "[Objection Handling Prompt]\n",
            "Prompt: How to handle this objection: Sure! Here's a sentence with a neutral sentiment:  \"The product arrived on time, but I haven't had a chance to use it yet.\"\n",
            "\n",
            "But here's the problem: The product is not a product. It's not even a \"product.\"\n",
            "\n",
            "[Post-Call Summary]\n",
            "Summary: Customer expressed concerns about pricing. Suggested offering a discount.\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "\n",
        "from transformers import pipeline, GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# 1. Real-Time Speech Analysis and Sentiment Detection\n",
        "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "\n",
        "def analyze_speech(speech):\n",
        "    result = sentiment_analyzer(speech)\n",
        "    sentiment = result[0][\"label\"]\n",
        "    confidence = result[0][\"score\"]\n",
        "    print(f\"\\n[Speech Analysis]\")\n",
        "    print(f\"Detected Sentiment: {sentiment} (Confidence: {confidence:.2f})\")\n",
        "    return sentiment, confidence\n",
        "\n",
        "\n",
        "# 2. CRM-Integrated Product Recommendation System\n",
        "crm_data = {\n",
        "    \"John Doe\": {\"past_purchases\": [\"Laptop\"], \"interests\": [\"Electronics\", \"Gaming\"]},\n",
        "    \"Jane Smith\": {\"past_purchases\": [\"Running Shoes\"], \"interests\": [\"Fitness\", \"Sports\"]}\n",
        "}\n",
        "\n",
        "def recommend_product(customer_name):\n",
        "    print(\"\\n[Product Recommendations]\")\n",
        "    if customer_name in crm_data:\n",
        "        customer = crm_data[customer_name]\n",
        "        recommendations = f\"Based on your interests in {customer['interests']}, we recommend checking out Gaming Headsets and Laptops!\"\n",
        "        print(recommendations)\n",
        "    else:\n",
        "        recommendations = \"Customer not found in CRM.\"\n",
        "        print(recommendations)\n",
        "    return recommendations\n",
        "\n",
        "\n",
        "# 3. Dynamic Question and Objection Handling Prompt Generator\n",
        "model_name = \"gpt2\"  # Use GPT-3 or GPT-4 in real implementation\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "def generate_prompt(objection):\n",
        "    print(\"\\n[Objection Handling Prompt]\")\n",
        "    input_text = f\"How to handle this objection: {objection}\"\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "    # Explicitly passing pad_token_id and attention_mask\n",
        "    outputs = model.generate(\n",
        "        input_ids,\n",
        "        max_length=60,\n",
        "        num_return_sequences=1,\n",
        "        pad_token_id=tokenizer.eos_token_id,  # Use eos_token_id for padding\n",
        "        attention_mask=None,  # GPT-2 doesn't use attention mask, so set to None\n",
        "         no_repeat_ngram_size=2,  # Prevent repeated n-grams (like the repetition issue)\n",
        "        temperature=0.7,  # Control randomness (0 is deterministic, 1 is more random)\n",
        "    )\n",
        "\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    print(f\"Prompt: {generated_text}\")\n",
        "    return generated_text\n",
        "\n",
        "\n",
        "# 4. Post-Call Summary and Insight Generation Module\n",
        "def generate_summary(speech_transcript):\n",
        "    print(\"\\n[Post-Call Summary]\")\n",
        "    # Mock summary generator\n",
        "    summary = f\"Summary: Customer expressed concerns about pricing. Suggested offering a discount.\"\n",
        "    print(summary)\n",
        "    return summary\n",
        "\n",
        "\n",
        "# Main Flow\n",
        "def ai_sales_assistant():\n",
        "    print(\"Welcome to the AI-Driven Sales Assistant!\")\n",
        "\n",
        "    # Input customer name\n",
        "    customer_name = input(\"\\nEnter customer name: \")\n",
        "\n",
        "    # Simulated sales call speech\n",
        "    speech = input(\"\\nEnter customer speech: \")\n",
        "\n",
        "    # Step 1: Analyze Speech Sentiment\n",
        "    sentiment, confidence = analyze_speech(speech)\n",
        "\n",
        "    # Step 2: Provide Product Recommendations\n",
        "    recommend_product(customer_name)\n",
        "\n",
        "    # Step 3: Generate Question and Objection Handling Prompt\n",
        "    generate_prompt(speech)\n",
        "\n",
        "    # Step 4: Generate Post-Call Summary\n",
        "    generate_summary(speech)\n",
        "\n",
        "\n",
        "# Run the assistant\n",
        "ai_sales_assistant()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAw_50t-QrhX",
        "outputId": "e07063b8-5999-4531-b828-54a1c97a1293"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "pip install transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVo7SzXOQrhY",
        "outputId": "2228cc97-ae17-490b-f17d-8e11ebd9dd89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected Sentiment: POSITIVE (Confidence: 1.00)\n",
            "Analyzing: \"I'm not sure if I want this product. It seems too expensive.\"\n",
            "Detected Sentiment: NEGATIVE (Confidence: 1.00)\n",
            "--------------------------------------------------\n",
            "Analyzing: \"This product is amazing! I can't wait to use it.\"\n",
            "Detected Sentiment: POSITIVE (Confidence: 1.00)\n",
            "--------------------------------------------------\n",
            "Analyzing: \"I'm really disappointed with the quality of this item.\"\n",
            "Detected Sentiment: NEGATIVE (Confidence: 1.00)\n",
            "--------------------------------------------------\n",
            "Analyzing: \"Can you tell me more about this feature? It sounds interesting.\"\n",
            "Detected Sentiment: POSITIVE (Confidence: 1.00)\n",
            "--------------------------------------------------\n",
            "Analyzing: \"The price seems fair, but I still need to think about it.\"\n",
            "Detected Sentiment: NEGATIVE (Confidence: 0.50)\n",
            "--------------------------------------------------\n",
            "Analyzing: \"I don't trust this brand based on my past experience.\"\n",
            "Detected Sentiment: NEGATIVE (Confidence: 1.00)\n",
            "--------------------------------------------------\n",
            "Analyzing: \"Wow, this is exactly what I've been looking for!\"\n",
            "Detected Sentiment: POSITIVE (Confidence: 1.00)\n",
            "--------------------------------------------------\n",
            "Analyzing: \"I think I might go for a competitor's product instead.\"\n",
            "Detected Sentiment: NEGATIVE (Confidence: 1.00)\n",
            "--------------------------------------------------\n",
            "Analyzing: \"I'm thrilled with the service I've received so far!\"\n",
            "Detected Sentiment: POSITIVE (Confidence: 1.00)\n",
            "--------------------------------------------------\n",
            "Analyzing: \"I'm feeling overwhelmed by the options. Can you simplify it for me?\"\n",
            "Detected Sentiment: POSITIVE (Confidence: 0.70)\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Sentiment analysis pipeline\n",
        "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "\n",
        "def analyze_speech(speech):\n",
        "    result = sentiment_analyzer(speech)\n",
        "    sentiment = result[0][\"label\"]\n",
        "    confidence = result[0][\"score\"]\n",
        "    print(f\"Detected Sentiment: {sentiment} (Confidence: {confidence:.2f})\")\n",
        "    return sentiment, confidence\n",
        "\n",
        "# Example input\n",
        "speech = \"I'm very much sure that I want this product\"\n",
        "analyze_speech(speech)\n",
        "\n",
        "# Example speech inputs and sentiment analysis\n",
        "speech_examples = [\n",
        "    \"I'm not sure if I want this product. It seems too expensive.\",\n",
        "    \"This product is amazing! I can't wait to use it.\",\n",
        "    \"I'm really disappointed with the quality of this item.\",\n",
        "    \"Can you tell me more about this feature? It sounds interesting.\",\n",
        "    \"The price seems fair, but I still need to think about it.\",\n",
        "    \"I don't trust this brand based on my past experience.\",\n",
        "    \"Wow, this is exactly what I've been looking for!\",\n",
        "    \"I think I might go for a competitor's product instead.\",\n",
        "    \"I'm thrilled with the service I've received so far!\",\n",
        "    \"I'm feeling overwhelmed by the options. Can you simplify it for me?\"\n",
        "]\n",
        "\n",
        "# Analyze each speech input\n",
        "for speech in speech_examples:\n",
        "    print(f\"Analyzing: \\\"{speech}\\\"\")\n",
        "    analyze_speech(speech)\n",
        "    print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "hR7rou6RQrhY",
        "outputId": "e6c7bc7c-c8b3-4fe3-b1a0-c4249b4d2752"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on your interests in ['Electronics', 'Gaming'], we recommend these products!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Based on your interests in ['Electronics', 'Gaming'], we recommend these products!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Mock CRM data\n",
        "crm_data = {\n",
        "    \"John Doe\": {\"past_purchases\": [\"Laptop\"], \"interests\": [\"Electronics\", \"Gaming\"]},\n",
        "    \"Jane Smith\": {\"past_purchases\": [\"Running Shoes\"], \"interests\": [\"Fitness\", \"Sports\"]}\n",
        "}\n",
        "\n",
        "def recommend_product(customer_name):\n",
        "    if customer_name in crm_data:\n",
        "        customer = crm_data[customer_name]\n",
        "        recommendations = f\"Based on your interests in {customer['interests']}, we recommend these products!\"\n",
        "        print(recommendations)\n",
        "    else:\n",
        "        print(\"Customer not found in CRM.\")\n",
        "    return recommendations\n",
        "\n",
        "# Example usage\n",
        "recommend_product(\"John Doe\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hif6sgk_QrhZ",
        "outputId": "3e1e031c-00ce-417f-bd42-34fc89da9391"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: How to handle this objection: This product is too expensive.\n",
            "\n",
            "I think the best way to deal with this is to get rid of the plastic packaging. If we could just replace it, we would be able to save a lot of money.\n"
          ]
        }
      ],
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Load pre-trained model and tokenizer\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "def generate_prompt(objection):\n",
        "    input_text = f\"How to handle this objection: {objection}\"\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "    # Generate output with settings to allow sampling\n",
        "    outputs = model.generate(\n",
        "        input_ids,\n",
        "        max_length=50,  # Limit the response length\n",
        "        num_return_sequences=1,  # Generate only one response\n",
        "        pad_token_id=tokenizer.eos_token_id,  # Set pad_token_id explicitly\n",
        "        no_repeat_ngram_size=2,  # Prevent repetition of n-grams\n",
        "        temperature=0.7,  # Control randomness (lower = less random)\n",
        "        do_sample=True,  # Enable sampling\n",
        "    )\n",
        "\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    print(f\"Prompt: {generated_text}\")\n",
        "\n",
        "# Example usage\n",
        "objection = \"This product is too expensive.\"\n",
        "generate_prompt(objection)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "pc7eyG-QQrhZ",
        "outputId": "49d37f75-9e06-46f4-c520-1bbad2a2d56d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: Customer expressed concerns about pricing. Suggested offering a discount.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Summary: Customer expressed concerns about pricing. Suggested offering a discount.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "def generate_summary(speech_transcript):\n",
        "    # Mock summary generator\n",
        "    summary = f\"Summary: Customer expressed concerns about pricing. Suggested offering a discount.\"\n",
        "    print(summary)\n",
        "    return summary\n",
        "\n",
        "# Example usage\n",
        "speech_transcript = \"The customer is worried about the cost of this product.\"\n",
        "generate_summary(speech_transcript)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxiW3JsJQrha",
        "outputId": "ac55c952-c89e-4359-c0f8-b42ec5221e40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Customer Speech: The customer is worried about the cost of this product.\n",
            "Summary: Customer expressed concerns about pricing. Suggested offering a discount or explaining financing options.\n",
            "\n",
            "Customer Speech: The customer is asking about the delivery timeline for the product.\n",
            "Summary: Customer was concerned about delivery timelines. Recommended expediting shipping or providing a tracking option.\n",
            "\n",
            "Customer Speech: The customer wants to know more about the features of the product.\n",
            "Summary: Customer had questions about product features. Suggested sharing a detailed brochure or demo.\n",
            "\n",
            "Customer Speech: The customer mentioned that a competitor's product is cheaper.\n",
            "Summary: Customer compared the product with a competitor. Highlighted unique selling points and value-added services.\n",
            "\n",
            "Customer Speech: The customer is concerned about the after-sales support for this product.\n",
            "Summary: Customer inquired about after-sales support. Reassured with details about warranty and customer support services.\n",
            "\n",
            "Customer Speech: The customer said they are working with a limited budget.\n",
            "Summary: Customer mentioned budget constraints. Suggested discussing payment plans or recommending a more affordable option.\n",
            "\n",
            "Customer Speech: The customer raised concerns about the reliability of the product.\n",
            "Summary: Customer was concerned about product quality. Shared testimonials and warranty information for reassurance.\n",
            "\n",
            "Customer Speech: The customer asked general questions without specific objections.\n",
            "Summary: General discussion about the product. No major concerns noted. Follow-up scheduled for further engagement.\n"
          ]
        }
      ],
      "source": [
        "def generate_summary(speech_transcript):\n",
        "    # Analyze the transcript and return a mock summary\n",
        "    if \"cost\" in speech_transcript or \"price\" in speech_transcript:\n",
        "        summary = \"Summary: Customer expressed concerns about pricing. Suggested offering a discount or explaining financing options.\"\n",
        "    elif \"delivery\" in speech_transcript or \"time\" in speech_transcript:\n",
        "        summary = \"Summary: Customer was concerned about delivery timelines. Recommended expediting shipping or providing a tracking option.\"\n",
        "    elif \"features\" in speech_transcript or \"functionality\" in speech_transcript:\n",
        "        summary = \"Summary: Customer had questions about product features. Suggested sharing a detailed brochure or demo.\"\n",
        "    elif \"comparison\" in speech_transcript or \"competitor\" in speech_transcript:\n",
        "        summary = \"Summary: Customer compared the product with a competitor. Highlighted unique selling points and value-added services.\"\n",
        "    elif \"support\" in speech_transcript or \"after-sales\" in speech_transcript:\n",
        "        summary = \"Summary: Customer inquired about after-sales support. Reassured with details about warranty and customer support services.\"\n",
        "    elif \"budget\" in speech_transcript or \"affordability\" in speech_transcript:\n",
        "        summary = \"Summary: Customer mentioned budget constraints. Suggested discussing payment plans or recommending a more affordable option.\"\n",
        "    elif \"quality\" in speech_transcript or \"reliability\" in speech_transcript:\n",
        "        summary = \"Summary: Customer was concerned about product quality. Shared testimonials and warranty information for reassurance.\"\n",
        "    else:\n",
        "        summary = \"Summary: General discussion about the product. No major concerns noted. Follow-up scheduled for further engagement.\"\n",
        "\n",
        "    print(summary)\n",
        "    return summary\n",
        "\n",
        "\n",
        "# Example Usage\n",
        "transcripts = [\n",
        "    \"The customer is worried about the cost of this product.\",\n",
        "    \"The customer is asking about the delivery timeline for the product.\",\n",
        "    \"The customer wants to know more about the features of the product.\",\n",
        "    \"The customer mentioned that a competitor's product is cheaper.\",\n",
        "    \"The customer is concerned about the after-sales support for this product.\",\n",
        "    \"The customer said they are working with a limited budget.\",\n",
        "    \"The customer raised concerns about the reliability of the product.\",\n",
        "    \"The customer asked general questions without specific objections.\"\n",
        "]\n",
        "\n",
        "for transcript in transcripts:\n",
        "    print(\"\\nCustomer Speech:\", transcript)\n",
        "    generate_summary(transcript)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBlbOtSXQrha",
        "outputId": "d436e41c-efe0-4cee-eef6-871d2ae4761d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Objection: This product is too expensive.\n",
            "Prompt: How to handle this objection: This product is too expensive.\n",
            "\n",
            "The problem is that the price of this product has been rising for years. The price is rising because of the fact that it is a product that is not only expensive, but also\n",
            "\n",
            "\n",
            "Objection: I don't think I need this product.\n",
            "Prompt: How to handle this objection: I don't think I need this product. I just want to know what it is.\n",
            "\n",
            "I'm not sure if I should have bought it. It's not a good product, and I'm sure it's\n",
            "\n",
            "\n",
            "Objection: I am worried about the quality of the product.\n",
            "Prompt: How to handle this objection: I am worried about the quality of the product. I have been using this product for about a year now and I can tell you that it is not as good as I expected. The only thing I would change is to\n",
            "\n",
            "\n",
            "Objection: I don't have enough information to decide.\n",
            "Prompt: How to handle this objection: I don't have enough information to decide.\n",
            "\n",
            "I'm not sure if this is a good idea or not. I'm sure that it's not a bad idea. But I think it is important to understand that\n",
            "\n",
            "\n",
            "Objection: Your competitor offers a better price.\n",
            "Prompt: How to handle this objection: Your competitor offers a better price.\n",
            "\n",
            "The problem is that you're not paying for the service. You're paying the price for it. And you can't afford to pay for a service that's not available to\n",
            "\n",
            "\n",
            "Objection: The delivery time is too long.\n",
            "Prompt: How to handle this objection: The delivery time is too long.\n",
            "\n",
            "The delivery times are too short. The time to deliver is not too fast. It is a long time. You can't get it to you. If you want to get\n",
            "\n",
            "\n",
            "Objection: I am not sure this fits my needs.\n",
            "Prompt: How to handle this objection: I am not sure this fits my needs. I have a lot of experience with the use of the word \"disgusting\" in the context of a sexual encounter. It is not a word that I use often,\n",
            "\n",
            "\n",
            "Objection: I need to consult my team before deciding.\n",
            "Prompt: How to handle this objection: I need to consult my team before deciding.\n",
            "\n",
            "I'm not sure if this is a good idea or not. I'm sure that it's not a bad idea. But I don't think it is. It\n",
            "\n",
            "\n",
            "Objection: I’ve had a bad experience with similar products.\n",
            "Prompt: How to handle this objection: I’ve had a bad experience with similar products. I have tried many different brands, and none of them are as good as the one I bought.\n",
            "\n",
            "I have also tried a few different products, but\n",
            "\n",
            "\n",
            "Objection: I don’t see the value in this product.\n",
            "Prompt: How to handle this objection: I don’t see the value in this product. I‖ve been using it for a while now and I have never had any problems with it. It is a great product and it is very easy to\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Load pre-trained model and tokenizer\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "def generate_prompt(objection):\n",
        "    \"\"\"\n",
        "    Generates a response to handle customer objections based on the input objection.\n",
        "\n",
        "    Parameters:\n",
        "    objection (str): Customer's objection or concern.\n",
        "\n",
        "    Returns:\n",
        "    str: AI-generated response for handling the objection.\n",
        "    \"\"\"\n",
        "    input_text = f\"How to handle this objection: {objection}\"\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "    # Explicitly set attention_mask and pad_token_id\n",
        "    attention_mask = torch.ones(input_ids.shape, device=input_ids.device)  # Attention mask to ignore padding\n",
        "    pad_token_id = tokenizer.eos_token_id  # EOS token as padding token\n",
        "\n",
        "    outputs = model.generate(\n",
        "        input_ids,\n",
        "        max_length=50,  # Limit the response length\n",
        "        num_return_sequences=1,\n",
        "        no_repeat_ngram_size=2,\n",
        "        pad_token_id=pad_token_id,  # Explicitly set pad_token_id\n",
        "        attention_mask=attention_mask,  # Explicitly set attention_mask\n",
        "    )\n",
        "\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    print(f\"\\nObjection: {objection}\")\n",
        "    print(f\"Prompt: {generated_text}\\n\")\n",
        "    return generated_text\n",
        "\n",
        "# Example objections\n",
        "objections = [\n",
        "    \"This product is too expensive.\",\n",
        "    \"I don't think I need this product.\",\n",
        "    \"I am worried about the quality of the product.\",\n",
        "    \"I don't have enough information to decide.\",\n",
        "    \"Your competitor offers a better price.\",\n",
        "    \"The delivery time is too long.\",\n",
        "    \"I am not sure this fits my needs.\",\n",
        "    \"I need to consult my team before deciding.\",\n",
        "    \"I’ve had a bad experience with similar products.\",\n",
        "    \"I don’t see the value in this product.\"\n",
        "]\n",
        "\n",
        "# Generate prompts for each objection\n",
        "for objection in objections:\n",
        "    generate_prompt(objection)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "DcJQnABcQrhh",
        "outputId": "0d13304b-6778-4312-d7de-1d893923842e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello John Doe, based on your past purchases (Laptop) and interests in Electronics, Gaming, we recommend the following products:\n",
            "Gaming Headset, Mechanical Keyboard, Gaming Console, VR Headset\n",
            "Hello Jane Smith, based on your past purchases (Running Shoes) and interests in Fitness, Sports, we recommend the following products:\n",
            "Yoga Mat, Resistance Bands, Football, Tennis Racket\n",
            "Hello Alice Johnson, based on your past purchases (Smartphone) and interests in Photography, Travel, we recommend the following products:\n",
            "DSLR Camera, Tripod, Travel Backpack, Noise-Cancelling Headphones\n",
            "Hello Bob Brown, based on your past purchases (Kitchen Blender) and interests in Cooking, Health, we recommend the following products:\n",
            "Air Fryer, Chef's Knife, Blender Bottles, Vitamin Supplements\n",
            "Hello Eve Davis, based on your past purchases (Smartwatch) and interests in Tech, Fitness, we recommend the following products:\n",
            "Smart Home Devices, Wireless Earbuds, Yoga Mat, Resistance Bands\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello Eve Davis, based on your past purchases (Smartwatch) and interests in Tech, Fitness, we recommend the following products:\\nSmart Home Devices, Wireless Earbuds, Yoga Mat, Resistance Bands'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Mock CRM data\n",
        "crm_data = {\n",
        "    \"John Doe\": {\"past_purchases\": [\"Laptop\"], \"interests\": [\"Electronics\", \"Gaming\"]},\n",
        "    \"Jane Smith\": {\"past_purchases\": [\"Running Shoes\"], \"interests\": [\"Fitness\", \"Sports\"]},\n",
        "    \"Alice Johnson\": {\"past_purchases\": [\"Smartphone\"], \"interests\": [\"Photography\", \"Travel\"]},\n",
        "    \"Bob Brown\": {\"past_purchases\": [\"Kitchen Blender\"], \"interests\": [\"Cooking\", \"Health\"]},\n",
        "    \"Eve Davis\": {\"past_purchases\": [\"Smartwatch\"], \"interests\": [\"Tech\", \"Fitness\"]},\n",
        "}\n",
        "\n",
        "def recommend_product(customer_name):\n",
        "    \"\"\"\n",
        "    Recommends products to the customer based on their past purchases and interests.\n",
        "\n",
        "    Parameters:\n",
        "    customer_name (str): Name of the customer in CRM data.\n",
        "\n",
        "    Returns:\n",
        "    str: Product recommendation message.\n",
        "    \"\"\"\n",
        "    if customer_name in crm_data:\n",
        "        customer = crm_data[customer_name]\n",
        "        past_purchases = \", \".join(customer[\"past_purchases\"])\n",
        "        interests = \", \".join(customer[\"interests\"])\n",
        "        recommendations = (\n",
        "            f\"Hello {customer_name}, based on your past purchases ({past_purchases}) \"\n",
        "            f\"and interests in {interests}, we recommend the following products:\\n\"\n",
        "        )\n",
        "        # Mock recommendations based on interests\n",
        "        interest_based_products = {\n",
        "            \"Electronics\": [\"Gaming Headset\", \"Mechanical Keyboard\"],\n",
        "            \"Gaming\": [\"Gaming Console\", \"VR Headset\"],\n",
        "            \"Fitness\": [\"Yoga Mat\", \"Resistance Bands\"],\n",
        "            \"Sports\": [\"Football\", \"Tennis Racket\"],\n",
        "            \"Photography\": [\"DSLR Camera\", \"Tripod\"],\n",
        "            \"Travel\": [\"Travel Backpack\", \"Noise-Cancelling Headphones\"],\n",
        "            \"Cooking\": [\"Air Fryer\", \"Chef's Knife\"],\n",
        "            \"Health\": [\"Blender Bottles\", \"Vitamin Supplements\"],\n",
        "            \"Tech\": [\"Smart Home Devices\", \"Wireless Earbuds\"],\n",
        "        }\n",
        "        # Compile product suggestions\n",
        "        suggested_products = []\n",
        "        for interest in customer[\"interests\"]:\n",
        "            if interest in interest_based_products:\n",
        "                suggested_products.extend(interest_based_products[interest])\n",
        "        recommendations += \", \".join(suggested_products)\n",
        "        print(recommendations)\n",
        "    else:\n",
        "        recommendations = f\"Customer {customer_name} not found in CRM.\"\n",
        "        print(recommendations)\n",
        "    return recommendations\n",
        "\n",
        "# Example usage\n",
        "recommend_product(\"John Doe\")\n",
        "recommend_product(\"Jane Smith\")\n",
        "recommend_product(\"Alice Johnson\")\n",
        "recommend_product(\"Bob Brown\")\n",
        "recommend_product(\"Eve Davis\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "rzLmChSUQrhh"
      },
      "outputs": [],
      "source": [
        "# 1. Real-Time Speech Analysis and Sentiment Detection\n",
        "# What is it? This module uses NLP to analyze customer speech during a sales call and detect the sentiment, such as positive, negative, or neutral, along with a confidence score.\n",
        "# Why is it used? To understand the emotional tone of the customer during a call, which helps sales representatives adjust their approach dynamically.\n",
        "# Where is it used? In live sales calls to identify customer sentiment in real-time and guide conversations effectively.\n",
        "# How does it work?\n",
        "# The pipeline from the transformers library is used to load a sentiment analysis model.\n",
        "# It evaluates the customer’s speech and outputs the sentiment with a confidence score.\n",
        "\n",
        "# 2. CRM-Integrated Product Recommendation System\n",
        "# What is it? This module provides personalized product recommendations based on customer information stored in a CRM, such as past purchases and interests.\n",
        "# Why is it used? To deliver tailored product suggestions, making the sales pitch more relevant and increasing the chances of conversion.\n",
        "# Where is it used?\n",
        "# E-commerce platforms for product recommendations.\n",
        "# Sales calls to suggest products or services based on customer preferences.\n",
        "# How does it work?\n",
        "# The CRM data contains customer profiles with past purchases and interests.\n",
        "# The module fetches customer details and suggests products aligning with their preferences.\n",
        "\n",
        "# 3. Dynamic Question and Objection Handling Prompt Generator\n",
        "# What is it? This module provides context-based prompts for handling customer objections, such as price concerns or brand trust issues.\n",
        "# Why is it used? To assist sales representatives in handling objections with effective strategies and maintaining customer trust.\n",
        "# Where is it used?\n",
        "# During sales calls when customers raise concerns or objections.\n",
        "# In customer support or service calls to guide agents.\n",
        "# How does it work?\n",
        "# The module uses a pre-trained language model (GPT-2, GPT-3, or GPT-4) to generate tailored objection-handling prompts based on customer concerns.\n",
        "# It takes the objection as input and generates a suitable response.\n",
        "\n",
        "# 4. Post-Call Summary and Insight Generation Module\n",
        "# What is it? This module generates a summary of the sales call, highlighting key points such as customer concerns, recommended actions, and insights for improvement.\n",
        "# Why is it used? To document the call for follow-up actions and to improve sales training by providing actionable insights.\n",
        "# Where is it used?\n",
        "# After sales or customer support calls to summarize the conversation.\n",
        "# In training programs to analyze real-world sales scenarios and improve future strategies.\n",
        "# How does it work?\n",
        "# The module takes the speech transcript and uses predefined logic or models to generate a brief summary.\n",
        "# It emphasizes critical aspects like customer objections and suggested resolutions.\n",
        "\n",
        "# How These Modules Work Together in the AI Sales Assistant\n",
        "# Real-Time Speech Analysis: Detects the sentiment of the customer's speech during the call.\n",
        "# Product Recommendations: Suggests products based on the customer's profile, ensuring relevance.\n",
        "# Objection Handling: Provides a prompt to handle customer objections effectively.\n",
        "# Post-Call Summary: Generates a summary of the entire call for documentation and future reference.\n",
        "\n",
        "# Additional Details\n",
        "# Integration:\n",
        "# These modules can be integrated into a live sales tool or CRM system.\n",
        "# They can work independently or as part of a pipeline to enhance the sales representative's efficiency.\n",
        "\n",
        "# Technologies Used:\n",
        "# Transformers library for sentiment analysis and objection handling.\n",
        "# CRM data storage for personalized recommendations.\n",
        "# Simple text processing for generating call summaries.\n",
        "\n",
        "# Future Enhancements:\n",
        "# Replace GPT-2 with GPT-3 or GPT-4 for better objection handling.\n",
        "# Use advanced machine learning models for more accurate sentiment detection.\n",
        "# Integrate with real CRM systems and databases.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}